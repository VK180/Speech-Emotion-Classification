# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QJ4SL2pgR33H6OTI0RsDr56Re7D695-q
"""

import streamlit as st
import numpy as np
import librosa
import tensorflow as tf
import pickle
import os

# Load model and preprocessing objects
@st.cache_resource
def load_model_and_preprocessors():
    model = tf.keras.models.load_model('emotion_ann_model.h5')
    with open('label_encoder.pkl', 'rb') as f:
        label_encoder = pickle.load(f)
    with open('scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    with open('top_indices.pkl', 'rb') as f:
        top_indices = pickle.load(f)
    return model, label_encoder, scaler, top_indices

model, label_encoder, scaler, top_indices = load_model_and_preprocessors()

# Feature extraction function (same as used in training)
def extract_comprehensive_features(file_path):
    try:
        audio, sample_rate = librosa.load(file_path, sr=None) # sr=None to keep original sample rate

        features_list = []

        # 1. MFCCs (40 coefficients)
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
        features_list.append(np.mean(mfccs, axis=1))
        features_list.append(np.std(mfccs, axis=1))

        # 2. Delta MFCCs
        mfccs_delta = librosa.feature.delta(mfccs)
        features_list.append(np.mean(mfccs_delta, axis=1))
        features_list.append(np.std(mfccs_delta, axis=1))

        # 3. Delta-Delta MFCCs
        mfccs_delta2 = librosa.feature.delta(mfccs, order=2)
        features_list.append(np.mean(mfccs_delta2, axis=1))
        features_list.append(np.std(mfccs_delta2, axis=1))

        # 4. Chroma Feature
        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)
        features_list.append(np.mean(chroma, axis=1))
        features_list.append(np.std(chroma, axis=1))

        # 5. MEL Spectrogram Feature
        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)
        mel_db = librosa.power_to_db(mel, ref=np.max) # Convert to dB scale
        features_list.append(np.mean(mel_db, axis=1))
        features_list.append(np.std(mel_db, axis=1))

        # 6. Spectral Contrast Feature
        contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)
        features_list.append(np.mean(contrast, axis=1))
        features_list.append(np.std(contrast, axis=1))

        # 7. Tonnetz Feature
        # Requires harmonic-percussive source separation for better results
        y_harmonic, y_percussive = librosa.effects.hpss(audio)
        tonnetz = librosa.feature.tonnetz(y=y_harmonic, sr=sample_rate)
        features_list.append(np.mean(tonnetz, axis=1))
        features_list.append(np.std(tonnetz, axis=1))

        # 8. Zero Crossing Rate (ZCR)
        zcr = librosa.feature.zero_crossing_rate(y=audio)
        features_list.append(np.mean(zcr, axis=1))
        features_list.append(np.std(zcr, axis=1))

        # 9. Root Mean Square (RMS) Energy
        rms = librosa.feature.rms(y=audio)
        features_list.append(np.mean(rms, axis=1))
        features_list.append(np.std(rms, axis=1))

        # Concatenate all features into a single vector
        features = np.concatenate(features_list)

        return features
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None


# Streamlit UI
st.title("Speech Emotion Recognition")
st.write("Upload a `.wav` audio file to predict the emotion.")

uploaded_file = st.file_uploader("Choose a .wav file", type=["wav"])

if uploaded_file is not None:
    # Save uploaded file to a temporary location
    temp_filename = "temp_uploaded.wav"
    with open(temp_filename, "wb") as f:
        f.write(uploaded_file.read())

    # Feature extraction
    features = extract_comprehensive_features(temp_filename)
    if features is not None:
        features_selected = features[top_indices]
        features_scaled = scaler.transform([features_selected])
        pred = model.predict(features_scaled)
        emotion = label_encoder.inverse_transform([np.argmax(pred)])
        st.success(f"**Predicted emotion:** {emotion[0]}")
    else:
        st.error("Feature extraction failed. Please try another file.")

    # Optionally, remove the temp file
    os.remove(temp_filename)